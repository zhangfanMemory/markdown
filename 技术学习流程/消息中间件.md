# rocketmq
## rocketmq如何保证消息不丢失
1. 从Producer的视角来看：如果消息未能正确的存储在MQ中，或者消费者未能正确的消费到这条消息，都是消息丢失
2. 从Broker的视角来看：如果消息已经存在Broker里面了，如何保证不会丢失呢（宕机、磁盘崩溃）
3. 从Consumer的视角来看：如果消息已经完成持久化了，但是Consumer取了，但是未消费成功且没有反馈，就是消息丢失

1. 从Producer分析：如何确保消息正确的发送到了Broker?
   1. 可以通过同步的方式阻塞式的发送，check SendStatus，状态超时或者失败，则会触发默认的2次重试
   2. 采取事务消息的投递方式，但是如果消息发送Ack失败的话，此消息会存储在CommitLog当中，但是对ConsumerQueue是不可见的
2. 从Broker分析：如果确保接收到的消息不会丢失?
   1. 消息支持持久化到Commitlog里面，即使宕机后重启，未消费的消息也是可以加载出来的
   2. Broker自身支持同步刷盘、异步刷盘的策略，可以保证接收到的消息一定存储在本地的内存中
   3. Broker集群支持 1主N从的策略，支持同步复制和异步复制的方式，同步复制可以保证即使Master 磁盘崩溃，消息仍然不会丢失
3. 从Cunmser分析：如何确保拉取到的消息被成功消费？
   1. Consumer自身维护一个持久化的offset，标记已经成功消费或者已经成功发回到broker的消息下标
   2. 如果Consumer消费失败，那么它会把这个消息发回给Broker，发回成功后，再更新自己的offset
   3. 如果Consumer和broker一起挂了，消息也不会丢失，因为consumer 里面的offset是定时持久化的，重启之后，继续拉取offset之前的消息到本地

## 消息重复
1. 消费端处理消息的业务逻辑保持幂等性
2. 保证每条消息都有唯一编号且保证消息处理成功与去重表的日志同时出现

**RocketMQ不保证消息不重复，如果你的业务需要保证严格的不重复消息，需要你自己在业务端去重**

## mq当broker增加的时候历史未消费消息如何分配
新增broker节点之后，会进行reblance，reblance主要操作是将原市所有的队列进行重新分配，但是历史消息不会重新分配；即：Broker 会尽可能地将队列均匀地分配到各个 Broker 节点上，但是这不会涉及历史消息的重新分配。

![](/技术学习流程/pic/2023-04-19-17-54-24.png)

# kafka
1. broker：存储
2. topic：消息分类
3. partition：topic的分区，一个topic有多个partition，不同的partition分别部署在不同的broker上
4. offset：消息在日志上的位置，代表消息的唯一序号
5. 其中consumer消费者必须属于一个group